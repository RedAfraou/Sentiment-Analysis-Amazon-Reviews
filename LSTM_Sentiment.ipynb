{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGVJ1a59Hjxn"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import keras\r\n",
        "from keras import Model\r\n",
        "from tensorflow.keras.layers import Flatten,LSTM,Dense,Flatten,Embedding\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from keras_preprocessing.text import Tokenizer\r\n",
        "from keras.initializers import glorot_uniform\r\n",
        "from sklearn import model_selection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUQ3ThBkJSBs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "6f28aaf4-3a28-4f2d-e306-f515b4950bf4"
      },
      "source": [
        "with open('train.csv', 'r') as file:\r\n",
        "  text = file.readlines()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-571403616c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF3JXVctJ4KP"
      },
      "source": [
        "x_train = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLNkAeN8KcB2",
        "outputId": "cadfa58e-345e-484c-f27f-0fc88bda306e"
      },
      "source": [
        "word = []\r\n",
        "label = []\r\n",
        "for n in text:\r\n",
        "  n = n.split(\",\")\r\n",
        "  if n[0] == '\"2\"':\r\n",
        "    label.append(1)\r\n",
        "  else:\r\n",
        "    label.append(0)\r\n",
        "  word.append(\"\".join(n[1:]))\r\n",
        "x_train['consumer_review'] = word\r\n",
        "x_train['polarity_label'] = label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rExhHLOach3T"
      },
      "source": [
        "_, x_set,_,y_set = model_selection.train_test_split(x_train['consumer_review'], x_train['polarity_label'], test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlKm6_CpdulA"
      },
      "source": [
        "**Cleaning the data:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrN3aeG9d1RY"
      },
      "source": [
        "def data_prep(in_tex):\r\n",
        "  #remove punctuation\r\n",
        "  out_tex = re.sub('[^a-zA-Z]', ' ', in_tex)\r\n",
        "  #convert upper case to lower case\r\n",
        "  out_tex = \"\".join(list(map(lambda x:x.lower(), out_tex)))\r\n",
        "  #remove single characters\r\n",
        "  out_tex = re.sub(r\"\\s+[a-aZ-Z]\\s+\", ' ', out_tex)\r\n",
        "\r\n",
        "  return out_tex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LChALoV8grRs"
      },
      "source": [
        "text_set = []\r\n",
        "for reviews in list(x_set):\r\n",
        "  text_set.append(data_prep(reviews))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm6c48ItiDwv"
      },
      "source": [
        "x_train = pd.DataFrame()\r\n",
        "x_train['consumer_review'] = text_set\r\n",
        "x_train['polarity_label'] = list(y_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxWcgSyAijkY"
      },
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_train[\"consumer_review\"], x_train[\"polarity_label\"], test_size = 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0rx4rH3jCz8"
      },
      "source": [
        "x_train = np.array(x_train.values.tolist())\r\n",
        "x_test = np.array(x_test.values.tolist())\r\n",
        "y_train = np.array(y_train.values.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsSAe206jtsW"
      },
      "source": [
        "**Applying the Tokenizer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJbPK_nyjrs3"
      },
      "source": [
        "#Tokenizer\r\n",
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(x_train)\r\n",
        "word_index = tokenizer.word_index\r\n",
        "total_size = len(word_index)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oua25uqUoFvc"
      },
      "source": [
        "x_train = tokenizer.texts_to_sequences(x_train)\r\n",
        "x_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc1yejSEwnEY"
      },
      "source": [
        "max_lenght = 100\r\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=max_lenght)\r\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=max_lenght)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNFkELPJxGkV"
      },
      "source": [
        "**Structuring the model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjZ8yImGxEqQ"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Embedding(total_size, 20, input_length = max_lenght))\r\n",
        "model.add(LSTM(32, dropout = 0.2, recurrent_dropout=0.2))\r\n",
        "model.add(Dense(1, activation = \"sigmoid\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhSflS-Hx1dg"
      },
      "source": [
        "**Compiling the model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FASy5b5dxz-Y",
        "outputId": "4ce363cc-42e3-4566-d1ea-ae1021d37417"
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['acc'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 20)           290740    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                6784      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 297,557\n",
            "Trainable params: 297,557\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82mBcQDGyK3e"
      },
      "source": [
        "**Training the model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QsVD21LyJ58",
        "outputId": "2f2826d7-dd01-4b04-87ec-a0e3ba9a6f43"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "19/19 [==============================] - 3s 147ms/step - loss: 0.1885 - acc: 0.9474 - val_loss: 0.4959 - val_acc: 0.8002\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 3s 136ms/step - loss: 0.1068 - acc: 0.9724 - val_loss: 0.5720 - val_acc: 0.8121\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 3s 135ms/step - loss: 0.0674 - acc: 0.9852 - val_loss: 0.6753 - val_acc: 0.8022\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 3s 135ms/step - loss: 0.0512 - acc: 0.9894 - val_loss: 0.7593 - val_acc: 0.8071\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 3s 133ms/step - loss: 0.0519 - acc: 0.9903 - val_loss: 0.6456 - val_acc: 0.8051\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 3s 138ms/step - loss: 0.0598 - acc: 0.9890 - val_loss: 0.8074 - val_acc: 0.7824\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 3s 135ms/step - loss: 0.0650 - acc: 0.9877 - val_loss: 0.4987 - val_acc: 0.7953\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 3s 133ms/step - loss: 0.0620 - acc: 0.9826 - val_loss: 0.8095 - val_acc: 0.7962\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 3s 133ms/step - loss: 0.0313 - acc: 0.9949 - val_loss: 0.7257 - val_acc: 0.7972\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 3s 134ms/step - loss: 0.0238 - acc: 0.9966 - val_loss: 0.9193 - val_acc: 0.7962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1d9c88588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjYPITf_yo_I"
      },
      "source": [
        "model.save(\"LSTM.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}